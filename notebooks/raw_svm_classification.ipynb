{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505e73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ok\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import joblib\n",
    "\n",
    "print('Imports ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29814b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "features_glcm_lbp_hsv.csv not found in working dir",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m csv = \u001b[33m'\u001b[39m\u001b[33mfeatures_glcm_lbp_hsv.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(csv):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in working dir\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m df = pd.read_csv(csv)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Extract/normalize label (case-insensitive H# pattern)\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: features_glcm_lbp_hsv.csv not found in working dir"
     ]
    }
   ],
   "source": [
    "# Load raw features CSV\n",
    "csv = '../data/features_glcm_lbp_hsv.csv'\n",
    "if not os.path.exists(csv):\n",
    "    raise FileNotFoundError(f'{csv} not found in working dir')\n",
    "df = pd.read_csv(csv)\n",
    "# Extract/normalize label (case-insensitive H# pattern)\n",
    "df['label'] = df['filename'].astype(str).str.extract(r'(?i)(h\\d+)')[0].str.upper().fillna('UNKNOWN')\n",
    "print('Loaded', csv, '->', df.shape)\n",
    "print('Label distribution:')\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# prepare X,y (exclude filename,label,label_code if present)\n",
    "exclude = {'filename','label','label_code'}\n",
    "feature_cols = [c for c in df.columns if c not in exclude]\n",
    "X = df[feature_cols].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'].values)\n",
    "print('Features:', len(feature_cols))\n",
    "print('Classes:', list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea733c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel=linear  Accuracy=0.6677  Precision=0.6700  Recall=0.6677  F1=0.6656\n",
      "Kernel=rbf     Accuracy=0.7683  Precision=0.7786  Recall=0.7683  F1=0.7660\n",
      "Kernel=poly    Accuracy=0.7180  Precision=0.7332  Recall=0.7180  F1=0.7166\n",
      "Saved best model (rbf) and scaler with prefix raw_\n",
      "Classification report (best):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          H1       0.94      0.96      0.95        69\n",
      "         H10       0.74      0.76      0.75        51\n",
      "          H2       0.81      0.83      0.82        69\n",
      "          H3       0.77      0.87      0.82        69\n",
      "          H4       0.71      0.93      0.81        69\n",
      "          H5       0.98      0.59      0.74        69\n",
      "          H6       0.70      0.75      0.73        69\n",
      "          H7       0.70      0.65      0.68        69\n",
      "          H8       0.75      0.63      0.68        65\n",
      "          H9       0.65      0.68      0.67        57\n",
      "\n",
      "    accuracy                           0.77       656\n",
      "   macro avg       0.78      0.77      0.76       656\n",
      "weighted avg       0.78      0.77      0.77       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate (same helper as in NCA notebook)\n",
    "def train_and_evaluate_raw(X, y, label_names=None, prefix='raw'):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    kernels=['linear','rbf','poly']\n",
    "    results = {}\n",
    "    for k in kernels:\n",
    "        clf = SVC(kernel=k, random_state=42, gamma='scale')\n",
    "        clf.fit(X_train_s, y_train)\n",
    "        y_pred = clf.predict(X_test_s)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        results[k] = {'model': clf, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'y_pred': y_pred}\n",
    "        print(f'Kernel={k:6s}  Accuracy={acc:.4f}  Precision={prec:.4f}  Recall={rec:.4f}  F1={f1:.4f}')\n",
    "    best_k = max(results.keys(), key=lambda kk: results[kk]['accuracy'])\n",
    "    best_model = results[best_k]['model']\n",
    "    joblib.dump(best_model, f'{prefix}_svm_best.joblib')\n",
    "    joblib.dump(scaler, f'{prefix}_scaler.joblib')\n",
    "    print(f'Saved best model ({best_k}) and scaler with prefix {prefix}_')\n",
    "    if label_names is not None:\n",
    "        print('Classification report (best):')\n",
    "        print(classification_report(y_test, results[best_k]['y_pred'], target_names=label_names, zero_division=0))\n",
    "    return results, best_model, scaler\n",
    "\n",
    "# Run quick baseline on raw features\n",
    "res_raw, best_raw, scaler_raw = train_and_evaluate_raw(X, y, label_names=le.classes_, prefix='raw')\n",
    "\n",
    "# ------------------ Robust GridSearchCV (stratified CV + pipeline) ------------------\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split for grid search evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC(random_state=42))])\n",
    "param_grid = [\n",
    "    { 'svc__kernel': ['rbf'], 'svc__C': [0.1, 1, 10, 100], 'svc__gamma': ['scale', 'auto', 0.01, 0.001] },\n",
    "    { 'svc__kernel': ['linear'], 'svc__C': [0.01, 0.1, 1, 10, 100] },\n",
    "    { 'svc__kernel': ['poly'], 'svc__C': [0.1, 1, 10], 'svc__degree': [2, 3], 'svc__gamma': ['scale', 'auto'] },\n",
    "]\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=cv, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "print('Running GridSearchCV (this may take a while)')\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "print('Best CV score:', gs.best_score_)\n",
    "# evaluate on held-out test set\n",
    "y_pred = gs.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy (best grid estimator): {acc_test:.4f}')\n",
    "print('Classification report (grid best):')\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "# save best pipeline\n",
    "joblib.dump(gs.best_estimator_, 'raw_svm_best_grid.joblib')\n",
    "print('Saved tuned pipeline -> raw_svm_best_grid.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw_feature_columns.json\n"
     ]
    }
   ],
   "source": [
    "# Optionally: save feature columns mapping for later use\n",
    "import json\n",
    "with open('raw_feature_columns.json','w') as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "print('Saved raw_feature_columns.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
